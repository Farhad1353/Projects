{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys                     # import libraries\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "                         \n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\\\n",
    "                            , VotingRegressor, StackingRegressor     # import sklearn libraries \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from utils import rgb2gray, get_regression_data, visualise_regression_data # import our libraries\n",
    "from assigning_library import read_csv_files, split_train_validation, split_features_labels, read_param\n",
    "from regression_library import low_high_param, show_features_impact, plot_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################################\n",
    "## This is Part 1 of the project where we read the train and test csv files and splittig them to features and labels ##\n",
    "#######################################################################################################################\n",
    "\n",
    "path_train_file = \"../Data/winequality-red-train.csv\"  # assigning the train.csv file path to a variable\n",
    "path_test_file = \"../Data/winequality-red-test.csv\"  # assigning the test.csv file path to a variable\n",
    "\n",
    "my_train_File, my_test_File = read_csv_files(path_train_file, path_test_file)  # reading the csv files using pandas\n",
    "                                                                       \n",
    "header, X_train, X_validation, Y_train, Y_validation\\\n",
    "= split_train_validation(my_train_File, split_rate=0.25)  # splitting the train.csv to train and validation arrays\n",
    "\n",
    "X_test, Y_test = split_features_labels(my_test_File) # splitting the test.csv file to features and label arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Progress :  0 %\n",
      "Number of estimator of 50 Maximum features of 1 and Maximum depth of 25                     gives accuracy score of 0.00%\n",
      "Best Score so far :  0 %\n",
      "Random Forest Progress :  3 %\n",
      "Number of estimator of 50 Maximum features of 1 and Maximum depth of 27                     gives accuracy score of 76.56%\n",
      "Best Score so far :  76.56 %\n",
      "Random Forest Progress :  7 %\n",
      "Number of estimator of 50 Maximum features of 1 and Maximum depth of 29                     gives accuracy score of 79.38%\n",
      "Best Score so far :  79.38 %\n",
      "Random Forest Progress :  11 %\n",
      "Number of estimator of 50 Maximum features of 2 and Maximum depth of 25                     gives accuracy score of 80.00%\n",
      "Best Score so far :  80.0 %\n",
      "Random Forest Progress :  14 %\n",
      "Number of estimator of 50 Maximum features of 2 and Maximum depth of 27                     gives accuracy score of 80.62%\n",
      "Best Score so far :  80.62 %\n",
      "Random Forest Progress :  18 %\n",
      "Number of estimator of 50 Maximum features of 2 and Maximum depth of 29                     gives accuracy score of 80.62%\n",
      "Best Score so far :  80.62 %\n",
      "Random Forest Progress :  22 %\n",
      "Number of estimator of 50 Maximum features of 3 and Maximum depth of 25                     gives accuracy score of 79.69%\n",
      "Best Score so far :  80.62 %\n",
      "Random Forest Progress :  25 %\n",
      "Number of estimator of 50 Maximum features of 3 and Maximum depth of 27                     gives accuracy score of 79.69%\n",
      "Best Score so far :  80.62 %\n",
      "Random Forest Progress :  29 %\n",
      "Number of estimator of 50 Maximum features of 3 and Maximum depth of 29                     gives accuracy score of 80.62%\n",
      "Best Score so far :  80.62 %\n",
      "Random Forest Progress :  33 %\n",
      "Number of estimator of 100 Maximum features of 1 and Maximum depth of 25                     gives accuracy score of 79.06%\n",
      "Best Score so far :  80.62 %\n",
      "Random Forest Progress :  37 %\n",
      "Number of estimator of 100 Maximum features of 1 and Maximum depth of 27                     gives accuracy score of 78.75%\n",
      "Best Score so far :  80.62 %\n",
      "Random Forest Progress :  40 %\n",
      "Number of estimator of 100 Maximum features of 1 and Maximum depth of 29                     gives accuracy score of 80.31%\n",
      "Best Score so far :  80.62 %\n",
      "Random Forest Progress :  44 %\n",
      "Number of estimator of 100 Maximum features of 2 and Maximum depth of 25                     gives accuracy score of 79.69%\n",
      "Best Score so far :  80.62 %\n",
      "Random Forest Progress :  48 %\n",
      "Number of estimator of 100 Maximum features of 2 and Maximum depth of 27                     gives accuracy score of 81.88%\n",
      "Best Score so far :  81.88 %\n",
      "Random Forest Progress :  51 %\n",
      "Number of estimator of 100 Maximum features of 2 and Maximum depth of 29                     gives accuracy score of 78.44%\n",
      "Best Score so far :  81.88 %\n",
      "Random Forest Progress :  55 %\n",
      "Number of estimator of 100 Maximum features of 3 and Maximum depth of 25                     gives accuracy score of 81.56%\n",
      "Best Score so far :  81.88 %\n",
      "Random Forest Progress :  59 %\n",
      "Number of estimator of 100 Maximum features of 3 and Maximum depth of 27                     gives accuracy score of 78.12%\n",
      "Best Score so far :  81.88 %\n",
      "Random Forest Progress :  62 %\n",
      "Number of estimator of 100 Maximum features of 3 and Maximum depth of 29                     gives accuracy score of 79.69%\n",
      "Best Score so far :  81.88 %\n",
      "Random Forest Progress :  66 %\n",
      "Number of estimator of 150 Maximum features of 1 and Maximum depth of 25                     gives accuracy score of 77.81%\n",
      "Best Score so far :  81.88 %\n",
      "Random Forest Progress :  70 %\n",
      "Number of estimator of 150 Maximum features of 1 and Maximum depth of 27                     gives accuracy score of 79.06%\n",
      "Best Score so far :  81.88 %\n",
      "Random Forest Progress :  74 %\n",
      "Number of estimator of 150 Maximum features of 1 and Maximum depth of 29                     gives accuracy score of 78.75%\n",
      "Best Score so far :  81.88 %\n",
      "Random Forest Progress :  77 %\n",
      "Number of estimator of 150 Maximum features of 2 and Maximum depth of 25                     gives accuracy score of 78.75%\n",
      "Best Score so far :  81.88 %\n",
      "Random Forest Progress :  81 %\n",
      "Number of estimator of 150 Maximum features of 2 and Maximum depth of 27                     gives accuracy score of 78.12%\n",
      "Best Score so far :  81.88 %\n",
      "Random Forest Progress :  85 %\n",
      "Number of estimator of 150 Maximum features of 2 and Maximum depth of 29                     gives accuracy score of 79.06%\n",
      "Best Score so far :  81.88 %\n",
      "Random Forest Progress :  88 %\n",
      "Number of estimator of 150 Maximum features of 3 and Maximum depth of 25                     gives accuracy score of 79.69%\n",
      "Best Score so far :  81.88 %\n",
      "Random Forest Progress :  92 %\n",
      "Number of estimator of 150 Maximum features of 3 and Maximum depth of 27                     gives accuracy score of 78.44%\n",
      "Best Score so far :  81.88 %\n",
      "Random Forest Progress :  96 %\n",
      "Number of estimator of 150 Maximum features of 3 and Maximum depth of 29                     gives accuracy score of 79.38%\n",
      "Best Score so far :  81.88 %\n",
      "\n",
      "               RandomForest performance \n",
      "            --------------------------------\n",
      "Best Regressor Score for Random Forest : 81.88%\n",
      "Best Estimator number :  100 \n",
      "Best Features number :  2 \n",
      "best_max_depth :  25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model : model  12  with score of  81.88 %\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################################\n",
    "############## This part is using Random Forest in Regression form(Parts 2 & 3 of the Project) ####################\n",
    "###################################################################################################################\n",
    "\n",
    "best_regr_score_randomforest = 0  # variable which shows the best scoring RandomForest model\n",
    "progress_randomforest = 0   # variable which indicates how far have we processed our RandomForest models\n",
    "regr_score_randomforest = 0 # variable which shows the score for each of the Random Forest model\n",
    "\n",
    "n_estimator_midpoint, max_features_midpoint, max_depth_midpoint\\\n",
    "                = read_param(\"../Data/RandomForest_reg.csv\", 3) # reading the parameters from 1st stage of RandomForest\n",
    "n_estimator_step_size = 50 # defining the step change of n_estimator moving from one model to another\n",
    "n_estimator_strarting_point, n_estimator_ending_point = low_high_param\\\n",
    "(n_estimator_midpoint, n_estimator_step_size, 3) # finding lowest and highest values for n_estimators of RandomForest\n",
    "\n",
    "max_features_step_size = 1 # defining the step change of max_features moving from one model to another\n",
    "max_features_starting_point, max_features_ending_point = low_high_param\\\n",
    "(max_features_midpoint,max_features_step_size, 3) # finding lowest and highest values for max_features of RandomForest\n",
    "    \n",
    "max_depth_step_size = 2 # defining the step change of max_depth moving from one model to another\n",
    "max_depth_starting_point, max_depth_ending_point = low_high_param\\\n",
    "(max_depth_midpoint,max_depth_step_size, 3) # finding lowest and highest values for depth_features of RandomForest\n",
    "\n",
    "randomforest_models = np.zeros((27,2)) # defining an array for accuracy scores\n",
    "model_idx = 0     # index for each model                           \n",
    "best_model_score = 0    # variable for the best score\n",
    "\n",
    "                ### training and testing(through validation sets) all the RandomForest models\n",
    "for n_estimator_idx in range(n_estimator_strarting_point, n_estimator_ending_point, n_estimator_step_size):             \n",
    "    for max_features_idx in range(max_features_starting_point, max_features_ending_point, max_features_step_size):      \n",
    "        for max_depth_idx in range(max_depth_starting_point, max_depth_ending_point, max_depth_step_size):  \n",
    "            os.system('cls')\n",
    "            print(\"Random Forest Progress : \",int(progress_randomforest),\"%\")  # showing the progress of the process\n",
    "            print(\"Number of estimator of {} Maximum features of {} and Maximum depth of {} \\\n",
    "                    gives accuracy score of {:.2f}%\".format(n_estimator_idx, max_features_idx, \\\n",
    "                    max_depth_idx, regr_score_randomforest*100))  # score of one single RandomForest model\n",
    "            print(\"Best Score so far : \", round(best_regr_score_randomforest*100,2), \"%\")\n",
    "            progress_randomforest += 100/27\n",
    "            randomforestregressor = RandomForestRegressor(n_estimators = n_estimator_idx,  \\\n",
    "                max_features = max_features_idx, max_depth = max_depth_idx) # assigning an instance of a RandomForest\n",
    "            randomforestregressor.fit(X_train, Y_train)  # fitting the train arrays to each RandomForest model\n",
    "            Y_prediction = np.around(randomforestregressor.predict(X_validation)) #predicting using the validation set\n",
    "            regr_score_randomforest = accuracy_score(Y_validation, Y_prediction) #accuaracy score for each model\n",
    "            randomforest_models[model_idx, 1] = regr_score_randomforest * 100 # saving the score for each model\n",
    "            randomforest_models[model_idx, 0] = model_idx                 # saving the index for each model\n",
    "            if regr_score_randomforest > best_regr_score_randomforest: # assessing if the new score is better \n",
    "                best_n_estimators_randomforest = n_estimator_idx      # than the previous best score\n",
    "                best_max_features_randomforest = max_features_idx \n",
    "                best_max_depth_randomforest = max_depth_idx  \n",
    "                best_regr_score_randomforest = regr_score_randomforest\n",
    "                best_model_score = randomforest_models[model_idx, 1]\n",
    "                best_model_idx = randomforest_models[model_idx, 0]\n",
    "            model_idx+=1 \n",
    "os.system('cls')\n",
    "print(\"\\n               RandomForest performance \")\n",
    "print(\"            --------------------------------\") # show the best model of RandomForest tested on validation set\n",
    "print(\"Best Regressor Score for Random Forest : {:.2f}%\".format(best_regr_score_randomforest*100)) \n",
    "print(\"Best Estimator number : \", best_n_estimators_randomforest, \"\\nBest Features number : \"\\\n",
    "      , best_max_features_randomforest, \"\\nbest_max_depth : \",best_max_depth_randomforest)\n",
    "\n",
    "plot_models(randomforest_models[:,0], randomforest_models[:,1], \"RandomForest-Models\", 'g') # Plot all the models\n",
    "\n",
    "print(\"Best model : model \",int(best_model_idx), \" with score of \", round(best_model_score,2), \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Progress :  0 %\n",
      "Number of estimator of 62      Learning Rate of 0.16         gives accuracy score of 0.00%\n",
      "Best Score so far :  0 %\n",
      "AdaBoost Progress :  4 %\n",
      "Number of estimator of 62      Learning Rate of 0.19         gives accuracy score of 57.81%\n",
      "Best Score so far :  57.81 %\n",
      "AdaBoost Progress :  8 %\n",
      "Number of estimator of 62      Learning Rate of 0.22         gives accuracy score of 61.25%\n",
      "Best Score so far :  61.25 %\n",
      "AdaBoost Progress :  12 %\n",
      "Number of estimator of 62      Learning Rate of 0.25         gives accuracy score of 60.00%\n",
      "Best Score so far :  61.25 %\n",
      "AdaBoost Progress :  16 %\n",
      "Number of estimator of 62      Learning Rate of 0.28         gives accuracy score of 60.31%\n",
      "Best Score so far :  61.25 %\n",
      "AdaBoost Progress :  20 %\n",
      "Number of estimator of 66      Learning Rate of 0.16         gives accuracy score of 61.56%\n",
      "Best Score so far :  61.56 %\n",
      "AdaBoost Progress :  24 %\n",
      "Number of estimator of 66      Learning Rate of 0.19         gives accuracy score of 61.56%\n",
      "Best Score so far :  61.56 %\n",
      "AdaBoost Progress :  28 %\n",
      "Number of estimator of 66      Learning Rate of 0.22         gives accuracy score of 60.94%\n",
      "Best Score so far :  61.56 %\n",
      "AdaBoost Progress :  32 %\n",
      "Number of estimator of 66      Learning Rate of 0.25         gives accuracy score of 61.88%\n",
      "Best Score so far :  61.88 %\n",
      "AdaBoost Progress :  36 %\n",
      "Number of estimator of 66      Learning Rate of 0.28         gives accuracy score of 59.06%\n",
      "Best Score so far :  61.88 %\n",
      "AdaBoost Progress :  40 %\n",
      "Number of estimator of 70      Learning Rate of 0.16         gives accuracy score of 58.13%\n",
      "Best Score so far :  61.88 %\n",
      "AdaBoost Progress :  44 %\n",
      "Number of estimator of 70      Learning Rate of 0.19         gives accuracy score of 58.44%\n",
      "Best Score so far :  61.88 %\n",
      "AdaBoost Progress :  48 %\n",
      "Number of estimator of 70      Learning Rate of 0.22         gives accuracy score of 61.56%\n",
      "Best Score so far :  61.88 %\n",
      "AdaBoost Progress :  52 %\n",
      "Number of estimator of 70      Learning Rate of 0.25         gives accuracy score of 62.19%\n",
      "Best Score so far :  62.19 %\n",
      "AdaBoost Progress :  56 %\n",
      "Number of estimator of 70      Learning Rate of 0.28         gives accuracy score of 59.38%\n",
      "Best Score so far :  62.19 %\n",
      "AdaBoost Progress :  60 %\n",
      "Number of estimator of 74      Learning Rate of 0.16         gives accuracy score of 59.38%\n",
      "Best Score so far :  62.19 %\n",
      "AdaBoost Progress :  64 %\n",
      "Number of estimator of 74      Learning Rate of 0.19         gives accuracy score of 59.69%\n",
      "Best Score so far :  62.19 %\n",
      "AdaBoost Progress :  68 %\n",
      "Number of estimator of 74      Learning Rate of 0.22         gives accuracy score of 61.88%\n",
      "Best Score so far :  62.19 %\n",
      "AdaBoost Progress :  72 %\n",
      "Number of estimator of 74      Learning Rate of 0.25         gives accuracy score of 60.00%\n",
      "Best Score so far :  62.19 %\n",
      "AdaBoost Progress :  76 %\n",
      "Number of estimator of 74      Learning Rate of 0.28         gives accuracy score of 61.25%\n",
      "Best Score so far :  62.19 %\n",
      "AdaBoost Progress :  80 %\n",
      "Number of estimator of 78      Learning Rate of 0.16         gives accuracy score of 62.50%\n",
      "Best Score so far :  62.5 %\n",
      "AdaBoost Progress :  84 %\n",
      "Number of estimator of 78      Learning Rate of 0.19         gives accuracy score of 62.19%\n",
      "Best Score so far :  62.5 %\n",
      "AdaBoost Progress :  88 %\n",
      "Number of estimator of 78      Learning Rate of 0.22         gives accuracy score of 60.94%\n",
      "Best Score so far :  62.5 %\n",
      "AdaBoost Progress :  92 %\n",
      "Number of estimator of 78      Learning Rate of 0.25         gives accuracy score of 60.00%\n",
      "Best Score so far :  62.5 %\n",
      "AdaBoost Progress :  96 %\n",
      "Number of estimator of 78      Learning Rate of 0.28         gives accuracy score of 60.62%\n",
      "Best Score so far :  62.5 %\n",
      "\n",
      "                  AdaBoost performance \n",
      "            --------------------------------\n",
      "Best Regressor Score for AdaBoost : 62.50%\n",
      "Best Estimator number :  74 \n",
      "Best Learning rate :  0.28\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model : model  19  with score of  62.5 %\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################################\n",
    "################### This part is using AdaBoost in Regression form(Parts 2 & 3 of the Project) ####################\n",
    "###################################################################################################################\n",
    "\n",
    "best_regr_score_adaboost = 0 # variable which shows the best scoring AdaBoost model\n",
    "progress_adaboost = 0  # variable which indicates how far have we processed our AdaBoost models\n",
    "regr_score_adaboost = 0 # variable which shows the score for each of the AdaBoost model\n",
    "\n",
    "n_estimator_midpoint, learning_rate_midpoint = read_param(\"../Data/AdaBoost_reg.csv\", 2) # reading the parameters from 1st stage of AdaBoost\n",
    "n_estimator_step_size = 4 # defining the step change of n_estimator moving from one model to another\n",
    "n_estimator_strarting_point, n_estimator_ending_point = low_high_param\\\n",
    "(n_estimator_midpoint, n_estimator_step_size, 2) # finding lowest and highest values for n_estimators of AdaBoost\n",
    "\n",
    "learning_rate_step_size = 3 # defining the step change of max_features moving from one model to another\n",
    "learning_rate_starting_point, learning_rate_ending_point = low_high_param\\\n",
    "(learning_rate_midpoint, learning_rate_step_size, 2) # finding lowest and highest values for learning_rate of AdaBoost\n",
    "adaboost_models = np.zeros((25,2)) # defining an array for accuracy scores\n",
    "model_idx = 0     # index for each model                           \n",
    "best_model_score = 0    # variable for the best score\n",
    "\n",
    "                ### training and testing(through validation sets) all the AdaBoost models\n",
    "for n_estimator_idx in range(n_estimator_strarting_point, n_estimator_ending_point, n_estimator_step_size):             \n",
    "    for learning_rate_idx in range(learning_rate_starting_point, learning_rate_ending_point, learning_rate_step_size):       \n",
    "        os.system('cls')\n",
    "        print(\"AdaBoost Progress : \",int(progress_adaboost),\"%\")  # showing the progress of the process\n",
    "        print(\"Number of estimator of {}      Learning Rate of {} \\\n",
    "        gives accuracy score of {:.2f}%\".format(n_estimator_idx, learning_rate_idx/100,\\\n",
    "        regr_score_adaboost*100))  # score of one single AdaBoost model\n",
    "        print(\"Best Score so far : \", round(best_regr_score_adaboost*100,2), \"%\")\n",
    "        progress_adaboost += 100/25\n",
    "        adaboostregressor = AdaBoostRegressor(n_estimators = n_estimator_idx,\\\n",
    "        learning_rate = learning_rate_idx/100) # assigning an instance of a AdaBoost\n",
    "        adaboostregressor.fit(X_train, Y_train)  # fitting the train arrays to each AdaBoost model\n",
    "        Y_prediction = np.around(adaboostregressor.predict(X_validation)) #predicting using the validation set\n",
    "        regr_score_adaboost = accuracy_score(Y_validation, Y_prediction) #accuaracy score for each model\n",
    "        adaboost_models[model_idx, 1] = regr_score_adaboost * 100 # saving the score for each model\n",
    "        adaboost_models[model_idx, 0] = model_idx    # saving the index for each model\n",
    "        if regr_score_adaboost > best_regr_score_adaboost: # assessing if the new score is better \n",
    "            best_n_estimators_adaboost = n_estimator_idx      # than the previous best score\n",
    "            best_learning_rate_adaboost = learning_rate_idx  \n",
    "            best_regr_score_adaboost = regr_score_adaboost\n",
    "            best_model_score = adaboost_models[model_idx, 1]\n",
    "            best_model_idx = adaboost_models[model_idx, 0]\n",
    "        model_idx+=1\n",
    "os.system('cls')\n",
    "print(\"\\n                  AdaBoost performance \")\n",
    "print(\"            --------------------------------\") # show the best model of AdaBoost tested on validation set\n",
    "print(\"Best Regressor Score for AdaBoost : {:.2f}%\".format(best_regr_score_adaboost*100)) \n",
    "print(\"Best Estimator number : \", best_n_estimators_adaboost, \"\\nBest Learning rate : \"\\\n",
    "      , best_learning_rate_adaboost/100)\n",
    "\n",
    "plot_models(adaboost_models[:,0], adaboost_models[:,1], \"AdaBoost-Models\", 'b') # Plot all the models\n",
    "\n",
    "print(\"Best model : model \",int(best_model_idx), \" with score of \", round(best_model_score,2), \"%\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting Progress :  0 %\n",
      "Number of estimator of 55     Learning rate of 0.11 and Maximum depth of 6                     gives accuracy score of 0.00%\n",
      "Best Score so far :  0 %\n",
      "GradientBoosting Progress :  3 %\n",
      "Number of estimator of 55     Learning rate of 0.11 and Maximum depth of 7                     gives accuracy score of 80.31%\n",
      "Best Score so far :  80.31 %\n",
      "GradientBoosting Progress :  7 %\n",
      "Number of estimator of 55     Learning rate of 0.11 and Maximum depth of 8                     gives accuracy score of 79.69%\n",
      "Best Score so far :  80.31 %\n",
      "GradientBoosting Progress :  11 %\n",
      "Number of estimator of 55     Learning rate of 0.13 and Maximum depth of 6                     gives accuracy score of 80.00%\n",
      "Best Score so far :  80.31 %\n",
      "GradientBoosting Progress :  14 %\n",
      "Number of estimator of 55     Learning rate of 0.13 and Maximum depth of 7                     gives accuracy score of 77.19%\n",
      "Best Score so far :  80.31 %\n",
      "GradientBoosting Progress :  18 %\n",
      "Number of estimator of 55     Learning rate of 0.13 and Maximum depth of 8                     gives accuracy score of 84.06%\n",
      "Best Score so far :  84.06 %\n",
      "GradientBoosting Progress :  22 %\n",
      "Number of estimator of 55     Learning rate of 0.15 and Maximum depth of 6                     gives accuracy score of 78.12%\n",
      "Best Score so far :  84.06 %\n",
      "GradientBoosting Progress :  25 %\n",
      "Number of estimator of 55     Learning rate of 0.15 and Maximum depth of 7                     gives accuracy score of 77.50%\n",
      "Best Score so far :  84.06 %\n",
      "GradientBoosting Progress :  29 %\n",
      "Number of estimator of 55     Learning rate of 0.15 and Maximum depth of 8                     gives accuracy score of 81.88%\n",
      "Best Score so far :  84.06 %\n",
      "GradientBoosting Progress :  33 %\n",
      "Number of estimator of 60     Learning rate of 0.11 and Maximum depth of 6                     gives accuracy score of 80.31%\n",
      "Best Score so far :  84.06 %\n",
      "GradientBoosting Progress :  37 %\n",
      "Number of estimator of 60     Learning rate of 0.11 and Maximum depth of 7                     gives accuracy score of 80.00%\n",
      "Best Score so far :  84.06 %\n",
      "GradientBoosting Progress :  40 %\n",
      "Number of estimator of 60     Learning rate of 0.11 and Maximum depth of 8                     gives accuracy score of 80.62%\n",
      "Best Score so far :  84.06 %\n",
      "GradientBoosting Progress :  44 %\n",
      "Number of estimator of 60     Learning rate of 0.13 and Maximum depth of 6                     gives accuracy score of 78.75%\n",
      "Best Score so far :  84.06 %\n",
      "GradientBoosting Progress :  48 %\n",
      "Number of estimator of 60     Learning rate of 0.13 and Maximum depth of 7                     gives accuracy score of 78.12%\n",
      "Best Score so far :  84.06 %\n",
      "GradientBoosting Progress :  51 %\n",
      "Number of estimator of 60     Learning rate of 0.13 and Maximum depth of 8                     gives accuracy score of 84.38%\n",
      "Best Score so far :  84.38 %\n",
      "GradientBoosting Progress :  55 %\n",
      "Number of estimator of 60     Learning rate of 0.15 and Maximum depth of 6                     gives accuracy score of 81.25%\n",
      "Best Score so far :  84.38 %\n",
      "GradientBoosting Progress :  59 %\n",
      "Number of estimator of 60     Learning rate of 0.15 and Maximum depth of 7                     gives accuracy score of 79.38%\n",
      "Best Score so far :  84.38 %\n",
      "GradientBoosting Progress :  62 %\n",
      "Number of estimator of 60     Learning rate of 0.15 and Maximum depth of 8                     gives accuracy score of 80.62%\n",
      "Best Score so far :  84.38 %\n",
      "GradientBoosting Progress :  66 %\n",
      "Number of estimator of 65     Learning rate of 0.11 and Maximum depth of 6                     gives accuracy score of 80.94%\n",
      "Best Score so far :  84.38 %\n",
      "GradientBoosting Progress :  70 %\n",
      "Number of estimator of 65     Learning rate of 0.11 and Maximum depth of 7                     gives accuracy score of 79.69%\n",
      "Best Score so far :  84.38 %\n",
      "GradientBoosting Progress :  74 %\n",
      "Number of estimator of 65     Learning rate of 0.11 and Maximum depth of 8                     gives accuracy score of 80.31%\n",
      "Best Score so far :  84.38 %\n",
      "GradientBoosting Progress :  77 %\n",
      "Number of estimator of 65     Learning rate of 0.13 and Maximum depth of 6                     gives accuracy score of 79.38%\n",
      "Best Score so far :  84.38 %\n",
      "GradientBoosting Progress :  81 %\n",
      "Number of estimator of 65     Learning rate of 0.13 and Maximum depth of 7                     gives accuracy score of 78.44%\n",
      "Best Score so far :  84.38 %\n",
      "GradientBoosting Progress :  85 %\n",
      "Number of estimator of 65     Learning rate of 0.13 and Maximum depth of 8                     gives accuracy score of 82.19%\n",
      "Best Score so far :  84.38 %\n",
      "GradientBoosting Progress :  88 %\n",
      "Number of estimator of 65     Learning rate of 0.15 and Maximum depth of 6                     gives accuracy score of 79.06%\n",
      "Best Score so far :  84.38 %\n",
      "GradientBoosting Progress :  92 %\n",
      "Number of estimator of 65     Learning rate of 0.15 and Maximum depth of 7                     gives accuracy score of 79.06%\n",
      "Best Score so far :  84.38 %\n",
      "GradientBoosting Progress :  96 %\n",
      "Number of estimator of 65     Learning rate of 0.15 and Maximum depth of 8                     gives accuracy score of 79.69%\n",
      "Best Score so far :  84.38 %\n",
      "\n",
      "             GradientBoosting performance \n",
      "            --------------------------------\n",
      "Best Regressor Score for Random Forest : 84.38%\n",
      "Best Estimator number :  60 \n",
      "Best Learning rate :  0.13 \n",
      "best_max_depth :  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model : model  13  with score of  84.38 %\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################################\n",
    "############## This part is using Gradientboosting in Regression form(Parts 2 & 3 of the Project) #################\n",
    "###################################################################################################################\n",
    "\n",
    "best_regr_score_gradientboosting = 0  # variable which shows the best scoring Gradientboosting model\n",
    "progress_gradientboosting = 0   # variable which indicates how far have we processed our Gradientboosting models\n",
    "regr_score_gradientboosting = 0 # variable which shows the score for each of the Gradientboosting model\n",
    "\n",
    "n_estimator_midpoint, learning_rate_midpoint, max_depth_midpoint\\\n",
    "                = read_param(\"../Data/Gradientboosting_reg.csv\", 3) # reading the parameters from 1st stage of Gradientboosting\n",
    "n_estimator_step_size = 5 # defining the step change of n_estimator moving from one model to another\n",
    "n_estimator_strarting_point, n_estimator_ending_point = low_high_param\\\n",
    "(n_estimator_midpoint, n_estimator_step_size, 3) # finding lowest and highest values for n_estimators of Gradientboosting\n",
    "\n",
    "learning_rate_step_size = 2 # defining the step change of learning_rate moving from one model to another\n",
    "learning_rate_starting_point, learning_rate_ending_point = low_high_param\\\n",
    "(learning_rate_midpoint,learning_rate_step_size, 3) # finding lowest and highest values for learning_rate of Gradientboosting\n",
    "    \n",
    "max_depth_step_size = 1 # defining the step change of max_depth moving from one model to another\n",
    "max_depth_starting_point, max_depth_ending_point = low_high_param\\\n",
    "(max_depth_midpoint,max_depth_step_size, 3) # finding lowest and highest values for depth_features of Gradientboosting\n",
    "gradientboost_models = np.zeros((27,2)) # defining an array for accuracy scores\n",
    "model_idx = 0     # index for each model                           \n",
    "best_model_score = 0    # variable for the best score    \n",
    "                ### training and testing(through validation sets) all the Gradientboosting models\n",
    "for n_estimator_idx in range(n_estimator_strarting_point, n_estimator_ending_point, n_estimator_step_size):             \n",
    "    for learning_rate_idx in range(learning_rate_starting_point, learning_rate_ending_point, learning_rate_step_size):      \n",
    "        for max_depth_idx in range(max_depth_starting_point, max_depth_ending_point, max_depth_step_size):  \n",
    "            os.system('cls')\n",
    "            print(\"GradientBoosting Progress : \",int(progress_gradientboosting),\"%\")  # showing the progress of the process\n",
    "            print(\"Number of estimator of {}     Learning rate of {} and Maximum depth of {} \\\n",
    "                    gives accuracy score of {:.2f}%\".format(n_estimator_idx, learning_rate_idx/100, \\\n",
    "                    max_depth_idx, regr_score_gradientboosting*100))  # score of one single Gradientboosting model\n",
    "            print(\"Best Score so far : \", round(best_regr_score_gradientboosting*100,2), \"%\")\n",
    "            progress_gradientboosting += 100/27\n",
    "            gradientboostingregressor = GradientBoostingRegressor(n_estimators = n_estimator_idx,  \\\n",
    "                learning_rate = learning_rate_idx/100, max_depth = max_depth_idx) # assigning an instance of a Gradientboosting\n",
    "            gradientboostingregressor.fit(X_train, Y_train)  # fitting the train arrays to each Gradientboosting model\n",
    "            Y_prediction = np.around(gradientboostingregressor.predict(X_validation)) #predicting using the validation set\n",
    "            regr_score_gradientboosting = accuracy_score(Y_validation, Y_prediction) #accuaracy score for each model\n",
    "            gradientboost_models[model_idx, 1] = regr_score_gradientboosting * 100 # saving the score for each model\n",
    "            gradientboost_models[model_idx, 0] = model_idx       # saving the index for each model\n",
    "            if regr_score_gradientboosting > best_regr_score_gradientboosting: # assessing if the new score is better \n",
    "                best_n_estimators_gradientboosting = n_estimator_idx      # than the previous best score\n",
    "                best_learning_rate_gradientboosting = learning_rate_idx \n",
    "                best_max_depth_gradientboosting = max_depth_idx  \n",
    "                best_regr_score_gradientboosting = regr_score_gradientboosting\n",
    "                best_model_score = gradientboost_models[model_idx, 1]\n",
    "                best_model_idx = gradientboost_models[model_idx, 0]\n",
    "            model_idx+=1 \n",
    "os.system('cls')\n",
    "print(\"\\n             GradientBoosting performance \")\n",
    "print(\"            --------------------------------\") # show the best model of Gradientboosting tested on validation set\n",
    "print(\"Best Regressor Score for Random Forest : {:.2f}%\".format(best_regr_score_gradientboosting*100)) \n",
    "print(\"Best Estimator number : \", best_n_estimators_gradientboosting, \"\\nBest Learning rate : \"\\\n",
    "      , best_learning_rate_gradientboosting/100, \"\\nbest_max_depth : \",best_max_depth_gradientboosting)\n",
    "\n",
    "plot_models(gradientboost_models[:,0], gradientboost_models[:,1], \"GradientBoost-Models\", 'r') # Plot all the models\n",
    "\n",
    "print(\"Best model : model \",int(best_model_idx), \" with score of \", round(best_model_score,2), \"%\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              StackingRegressor performance \n",
      "            --------------------------------\n",
      "Please wait few moments for the final result...\n",
      "Regressor Score for StackingRegressor : 81.88%\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################################\n",
    "##################### This part is implementing StackingRegressor(Part 4 of the project) ##########################\n",
    "###################################################################################################################\n",
    "\n",
    "######### Assigning the best performed HyperParameters in the RandomForest, AdaBoost and GradientBoosting ##########\n",
    "reg1 = RandomForestRegressor(n_estimators = best_n_estimators_randomforest\\\n",
    "    ,  max_features = best_max_features_randomforest, max_depth = best_max_depth_randomforest)\n",
    "reg2 = AdaBoostRegressor(n_estimators = best_n_estimators_adaboost,  learning_rate = best_learning_rate_adaboost/100)\n",
    "reg3 = GradientBoostingRegressor(n_estimators = best_n_estimators_gradientboosting\\\n",
    "    ,  learning_rate = best_learning_rate_gradientboosting/100, max_depth = best_max_depth_gradientboosting)\n",
    "\n",
    "os.system('cls')\n",
    "print(\"\\n              StackingRegressor performance on validation sets \")\n",
    "print(\"            -------------------------------------------------------\")\n",
    "stackingregressor = StackingRegressor(estimators=[('rf', reg1), ('ad', reg2), ('gb', reg3)])\n",
    "stackingregressor = stackingregressor.fit(X_train, Y_train)        ### Fitting the StackingRegressor model #####  \n",
    "Y_pred = np.around(stackingregressor.predict(X_validation)) ##### Predicting the Labels based on the test features #####\n",
    "ensemble_score = accuracy_score(Y_validation, Y_pred)  ##### Calulating the accuracy of each model ####\n",
    "\n",
    "print(\"Regressor Score for StackingRegressor : {:.2f}%\".format(ensemble_score*100))  ## showing the ensemble score ##\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor Score for StackingRegressor : 67.61%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n              StackingRegressor performance on test sets \")\n",
    "print(\"            ---------------------------------------------------\")\n",
    "\n",
    "Y_pred = np.around(stackingregressor.predict(X_test)) ##### Predicting the Labels based on the test features #####\n",
    "ensemble_score = accuracy_score(Y_test, Y_pred)  ##### Calulating the accuracy of each model ####\n",
    "\n",
    "print(\"Regressor Score for StackingRegressor : {:.2f}%\".format(ensemble_score*100))  ## showing the ensemble score ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            Rank Highest impacting features \n",
      "          --------------------------------------\n",
      "Alcohol               with weight of   1.7  and  positive imapct\n",
      "Sulphates             with weight of   1.3  and  positive imapct\n",
      "Total sulfur dioxide  with weight of   1.2  and  negative imapct\n",
      "Volatile acidity      with weight of   1.1  and  negative imapct\n",
      "Chlorides             with weight of   1.0  and  negative imapct\n",
      "Free sulfur dioxide   with weight of   0.6  and  positive imapct\n",
      "Fixed acidity         with weight of   0.5  and  positive imapct\n",
      "Ph                    with weight of   0.4  and  negative imapct\n",
      "Density               with weight of   0.3  and  negative imapct\n",
      "Citric acid           with weight of   0.3  and  negative imapct\n",
      "Residual sugar        with weight of   0.2  and  positive imapct\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################################\n",
    "########## Using Linear Regression to represent the features impact on the labels(Part 6 of the project) ##########\n",
    "###################################################################################################################\n",
    "os.system('cls')\n",
    "linearregression = LinearRegression()\n",
    "linearregression.fit(X_train, Y_train) ### Fitting the LinearRegression model #####\n",
    "\n",
    "Y_pred = np.around(linearregression.predict(X_validation))  ##### Predicting the Labels based on the test features #####\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "######## Showing the list of features ranked based the the impact to the prediction ############\n",
    "show_features_impact(linearregression.coef_, X_train, header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
